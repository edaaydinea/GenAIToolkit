{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe9ba91",
   "metadata": {},
   "source": [
    "# Course Overview\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "This extensive AI course offers a comprehensive curriculum, guiding learners from foundational AI principles (machine learning, deep learning, LLMs, tokens) through advanced prompt engineering, and into a wide array of practical applications using tools like ChatGPT. It covers generative AI for images and video (Dall-E, Midjourney, Stable Diffusion, Adobe Firefly), custom GPT and chatbot development, programming with AI assistance, exploring the LLM market beyond ChatGPT, and concludes with monetization strategies, ethical considerations, and the future of AI.\n",
    "\n",
    "### **Highlights**\n",
    "\n",
    "- **Comprehensive AI Fundamentals**: The course initiates with AI basics, covering machine learning, deep learning, neural networks, and the architecture of Large Language Models (LLMs) such as ChatGPT, Gemini, and Llama, along with essential concepts like tokens and the evolution of LLM capabilities.\n",
    "- **Mastery in Prompt Engineering**: A significant emphasis is placed on prompt engineering, progressing from foundational techniques (structured, instruction, role, shot prompting) to advanced strategies including Chain of Thought, Self-Consistency, Tree of Thought, system prompts (custom instructions), and other nuanced methods like bracket and sequence prompting.\n",
    "- **Diverse Real-World ChatGPT Applications**: The curriculum explores a multitude of practical uses for ChatGPT, ranging from text generation, summarization, and translation to aiding in learning new subjects (e.g., Excel, blockchain), coding assistance (HTML, Python), data analysis and visualization, career advancement (job searches, interview preparation), and creative pursuits like songwriting.\n",
    "- **In-depth Generative AI for Visuals**: Extensive coverage is dedicated to diffusion models for image creation, featuring detailed modules on Dall-E (including GenID for consistency, inpainting/outpainting), Adobe Firefly (with its integration into Adobe's suite for generative fill), Midjourney (from beginner commands to advanced techniques like chaos, niji, character consistency, and permutation prompting), and Stable Diffusion (leveraging Leonardo AI, ControlNet, LoRA training, SDXL Turbo for real-time generation). Text-to-video tools are also introduced.\n",
    "- **Development of Custom AI Solutions**: Learners will advance to building their own AI tools, including the creation of custom GPTs enhanced with actions (via Zapier and direct API calls), fine-tuning LLMs for specific tasks, and developing deployable chatbots using platforms like OpenAI Assistant API, Flowise, and Node.js, including web embedding.\n",
    "- **Voice Synthesis and Creative Media**: The course delves into text-to-speech technologies, highlighting platforms like ElevenLabs, and further explores combining these with visual AI tools for applications such as voice cloning and creating deepfakes (using D-ID, Stable Diffusion Deforum). AI music creation is also touched upon.\n",
    "- **Broad LLM Ecosystem Awareness**: Beyond the primary focus on ChatGPT, the course provides insights into the wider LLM landscape, discussing competitors and notable open-source models such as Google Gemini, Microsoft Copilot, Anthropic's Claude, Grok, and models accessible via Hugging Face like Mistral Mixtral and Llama 2.\n",
    "- **AI-Assisted Programming and Data Analysis**: A key component is leveraging AI for programming tasks, with introductions to Replit, GitHub, and Google Colab, alongside practical exercises in learning HTML, debugging code, Python programming, and developing Chrome extensions. Using ChatGPT for advanced data analysis and visualization through its code interpretation features is also thoroughly covered.\n",
    "- **Focus on Monetization and Career Building**: A dedicated section guides students on how to monetize their acquired AI skills through various avenues such as freelancing (Fiverr, Upwork), selling prompts (PromptBase), AI consulting, creating and selling chatbots, and leveraging AI for business growth (lead generation, understanding metrics like CAC/LTV).\n",
    "- **Ethical Framework and Future Trends**: The course responsibly addresses crucial topics like copyright issues, ethical dilemmas in AI development and deployment, and the potential downsides of AI, ensuring a balanced perspective alongside discussions of future advancements.\n",
    "- **Extensive Tool and Platform Familiarity**: Students will gain hands-on experience with a wide range of AI tools and platforms, including ChatGPT (all its versions and features), Replit, GitHub, Google Colab, Zapier, Flowise, Node.js, various LLM APIs, Hugging Face, Leonardo AI, Discord (as an interface for Midjourney), and Adobe Creative Suite's AI features.\n",
    "\n",
    "### **Conceptual Understanding**\n",
    "\n",
    "- **Pedagogical Approach: From Foundational Knowledge to Applied Creation and Specialization**\n",
    "    1. **Why is this structure important?** The course employs a progressive learning structure that begins with fundamental AI concepts (the \"what\" and \"why\"). It then builds practical skills by teaching how to effectively interact with and instruct these models (prompt engineering). Following this, it immerses learners in a vast array of real-world applications across diverse domains (the \"how-to\" and \"what-for\"). Finally, it culminates in empowering students to create their own AI tools, models, and even businesses, fostering innovation and specialization. This holistic approach ensures a deep and actionable understanding of AI.\n",
    "    2. **How does it connect to real-world tasks, problems, or applications?** This structured learning journey mirrors the trajectory of a data science or AI professional. Initial understanding of core principles is essential. Effective application of existing tools for specific tasks follows. Ultimately, the goal for many is to develop bespoke AI solutions—custom models, automated workflows, new AI-driven products—that address unique challenges or capitalize on new opportunities in their respective fields. The course's breadth also prepares individuals for the multidisciplinary nature of many AI roles.\n",
    "    3. **Which related techniques or areas should be studied alongside this concept (or as a result of this structure)?** Given the comprehensive nature of the course, graduates would be well-positioned to pursue specialized advanced studies or professional development in numerous areas. Depending on their interest, this could include: advanced machine learning algorithms, specialized NLP techniques, deep learning architectures, computer vision research, MLOps for robust model deployment and management, dedicated courses on AI ethics and governance, specific programming paradigms for AI (e.g., advanced Python, C++ for performance), or business development for AI startups.\n",
    "\n",
    "### **Reflective Questions**\n",
    "\n",
    "1. **Application:** If a marketing professional aims to leverage AI for enhancing campaign creativity and automating content generation (both text and visuals), which specific sections of this course would offer the most direct value?\n",
    "    - *Answer:* Sections 2-7 (AI Basics and extensive Prompt Engineering), 8-10 (Real-world uses, ChatGPT for Text/Writing, SEO), 30-44 (Diffusion Models, Dall-E, Adobe Firefly, Midjourney, Stable Diffusion for image/video generation), and 49 (Making Money - for campaign ROI) would be most directly valuable. These cover understanding LLMs, crafting effective prompts for desired outputs, specific writing/SEO applications, and a deep dive into generating diverse visual content.\n",
    "2. **Teaching:** How would you articulate the importance of Section 22 (AI Automation Agency / Chatbots) to an aspiring software developer who is skeptical about \"no-code/low-code\" AI solutions like Flowise?\n",
    "    - *Answer:* While you have strong coding skills, Section 22, covering tools like Flowise alongside API usage, demonstrates how to rapidly prototype and deploy AI solutions like chatbots. Understanding these platforms allows you to leverage pre-built components for common tasks, freeing you up to focus your advanced coding skills on more complex custom integrations (like the Google Search API mentioned, or backend logic), ultimately enabling you to deliver value to clients or your employer much faster and more efficiently.\n",
    "3. **Extension:** After completing this course, particularly the sections on custom GPTs (17), making own models (20), and training LoRAs (44), what kind of unique, niche AI application could a student endeavor to create by combining these skills?\n",
    "    - *Answer:* A student could create a highly specialized \"Historical Architectural Style Advisor\" GPT. This would involve fine-tuning an LLM (Section 20) on architectural history texts, training a LoRA (Section 44) on images of specific architectural elements (e.g., Gothic, Art Deco), and then building a custom GPT (Section 17) that can take a user's vague description or a modern building image, identify potential historical influences, generate text describing these styles, and even use the LoRA-infused image model (via an API call if needed) to generate new visual examples or modifications reflecting those historical styles.\n",
    "\n",
    "# My Goal and quick Tipp\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "The instructor outlines a primary goal of disseminating comprehensive AI knowledge, enabling students to progress from foundational concepts to advanced applications like training custom AI models, building deployable chatbots, creating AI art, and leveraging AI for professional and entrepreneurial success. A key learning tip offered is to adjust video playback speed to maintain optimal cognitive engagement and learning efficiency, with a commitment to keep the course updated and support a collaborative student community.\n",
    "\n",
    "### **Highlights**\n",
    "\n",
    "- **Comprehensive AI Skill Development**: The course is designed to transition students from beginners to experts, covering AI fundamentals and progressing to advanced skills such as training personalized AI models (e.g., Stable Diffusion for custom image generation), developing web-integrable chatbots, and creating sophisticated custom GPTs with API integrations (e.g., automating emails via Google accounts).\n",
    "- **Emphasis on Practical Application and Entrepreneurship**: A core objective is to equip students with the ability to apply AI for tangible results, including enhancing productivity, developing AI-driven applications, generating business leads, creating revenue streams (e.g., via the GPT store), and potentially pursuing careers as AI consultants.\n",
    "- **Community-Focused Collaborative Learning**: The instructor strongly advocates for building an active AI community within the course, believing that shared learning, interaction (e.g., through Q&A sections), and mutual support significantly enhance the educational outcomes for all participants.\n",
    "- **Learning Efficiency Tip: Adjust Video Speed**: A practical piece of advice given to learners is to increase the playback speed of course videos (up to 2x). This technique is suggested not merely for time-saving but as a cognitive strategy to keep the brain fully engaged with the material, thereby minimizing distractions and improving focus.\n",
    "- **Commitment to Current and Relevant Content**: The instructor assures students that the course will be regularly updated with new lectures and materials to reflect the latest advancements and trends in the rapidly evolving field of AI, ensuring its long-term value.\n",
    "- **Active Instructor Support and Iterative Improvement**: Students are encouraged to actively participate by asking questions, suggesting topics for new lectures, and providing course reviews. This indicates a responsive support system and a feedback loop that contributes to the ongoing improvement and relevance of the course content.\n",
    "\n",
    "### **Conceptual Understanding**\n",
    "\n",
    "- **Learning Optimization via Cognitive Engagement (Video Speed Adjustment)**\n",
    "    1. **Why is this concept important?** This tip addresses a common challenge in self-paced video learning: maintaining focus. The instructor's reasoning is that if the information flow is too slow for an individual's cognitive processing speed, the brain has spare capacity and may wander to unrelated thoughts, reducing learning effectiveness. Adjusting video speed can help align the information delivery rate with the learner's optimal processing ability, thus sustaining attention and improving comprehension.\n",
    "    2. **How does it connect to real-world tasks, problems, or applications?** This principle of matching information intake to processing capacity is broadly applicable. For data science students and professionals who consume a lot of video content (webinars, tutorials, conference talks), finding the right speed can significantly enhance learning efficiency. It's about optimizing a limited resource – time – to absorb a high volume of complex information effectively.\n",
    "    3. **Which related techniques or areas should be studied alongside this concept?** To further optimize learning, students might explore:\n",
    "        - **Active Learning Strategies:** Such as taking notes during videos, pausing to summarize concepts, or attempting to predict what comes next.\n",
    "        - **Metacognition:** Developing an awareness of one's own learning processes and identifying what speeds or methods work best.\n",
    "        - **Time Management Techniques:** Like the Pomodoro Technique, to structure study sessions and maintain high focus during learning blocks.\n",
    "        - **Cognitive Load Theory:** Understanding how working memory limitations can affect learning and how to manage information complexity.\n",
    "\n",
    "### **Reflective Questions**\n",
    "\n",
    "1. **Application:** Beyond watching course videos, in what other specific learning or professional development activity could you apply the principle of matching information intake speed to your cognitive capacity to improve focus and efficiency?\n",
    "    - *Answer:* This principle can be valuable when listening to data science podcasts or industry audiobooks by adjusting playback speed, or when reviewing recordings of lengthy technical webinars or team meetings to quickly extract key information during segments that are paced slower than one's processing ability.\n",
    "2. **Teaching:** How would you explain the instructor's \"brain capacity\" argument for increasing video speed to a fellow student who is hesitant and generally prefers learning at a slower, more deliberate pace?\n",
    "    - *Answer:* The idea is that our brains are always \"on\" and actively seeking input; if a video provides information too slowly, your brain might have leftover attention that it then directs to other thoughts, causing distraction from the lesson. Experimenting with a slightly faster speed could actually help you focus *more* intensely on the video content by keeping your brain more fully occupied with the material, though it's important to find a speed that feels engaging rather than overwhelming.\n",
    "\n",
    "# All important Links in one spot\n",
    "\n",
    "**All Important Links in One Spot**\n",
    "\n",
    "**ChatGPT**\n",
    "- [ChatGPT](https://chat.openai.com/)https://chat.openai.com/)\n",
    "\n",
    "**LLM Basics**\n",
    "- [What are Tokens](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)- [What are Tokens](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)\n",
    "- [Token Pricing](https://openai.com/pricing#language-models)g](https://openai.com/pricing#language-models)\n",
    "- [Tokenizer](https://platform.openai.com/tokenizer)- [Tokenizer](https://platform.openai.com/tokenizer)\n",
    "- [RLHF](https://huggingface.co/blog/rlhf)\n",
    "\n",
    "**Prompt Engineering Guides**\n",
    "- [Prompting Guide](https://www.promptingguide.ai/)- [Prompting Guide](https://www.promptingguide.ai/)\n",
    "- [Learn Prompting](https://learnprompting.org/docs/intro)ocs/intro)\n",
    "- [Tree of Thoughts Paper](https://arxiv.org/abs/2305.10601)- [Tree of Thoughts Paper](https://arxiv.org/abs/2305.10601)\n",
    "- [Sparse Priming Representations GitHub Repo](https://github.com/daveshap/SparsePrimingRepresentations)ub Repo](https://github.com/daveshap/SparsePrimingRepresentations)\n",
    "\n",
    "**Research Studies**\n",
    "- [arXiv](https://arxiv.org/)- [arXiv](https://arxiv.org/)\n",
    "\n",
    "**AI Content Detector**\n",
    "- [Writer AI Content Detector](https://writer.com/ai-content-detector/)//writer.com/ai-content-detector/)\n",
    "\n",
    "**Advanced Data Analysis and Plugins**\n",
    "- [ChatGPT Plugins](https://openai.com/blog/chatgpt-plugins)- [ChatGPT Plugins](https://openai.com/blog/chatgpt-plugins)\n",
    "- [Advanced Data Analysis (ChatGPT Enterprise)](https://help.openai.com/en/articles/8437071-advanced-data-analysis-chatgpt-enterprise-version)/articles/8437071-advanced-data-analysis-chatgpt-enterprise-version)\n",
    "\n",
    "**Platforms for AI, Development, and Coder AI, Development, and Code**\n",
    "- [Replit](https://replit.com/~)- [Replit](https://replit.com/~)\n",
    "- [GitHub](https://github.com/)/github.com/)\n",
    "- [Google Colab](https://colab.research.google.com/)- [Google Colab](https://colab.research.google.com/)\n",
    "- [Hugging Face](https://huggingface.co/)/huggingface.co/)\n",
    "\n",
    "**Zapier**\n",
    "- [Zapier Website](https://zapier.com/)- [Zapier Website](https://zapier.com/)\n",
    "- [Zapier API Keys for GPTs](https://actions.zapier.com/docs/platform/gpt)tions.zapier.com/docs/platform/gpt)\n",
    "- [Zapier AI Actions](https://actions.zapier.com/gpt/actions/)- [Zapier AI Actions](https://actions.zapier.com/gpt/actions/)\n",
    "\n",
    "**ChatGPT Team**\n",
    "- [ChatGPT Team](https://openai.com/blog/introducing-chatgpt-team)\n",
    "\n",
    "**OpenAI API**\n",
    "- [OpenAI API Overview](https://platform.openai.com/docs/overview)- [OpenAI API Overview](https://platform.openai.com/docs/overview)\n",
    "- [OpenAI Playground](https://platform.openai.com/playground)//platform.openai.com/playground)\n",
    "- [Fine-Tuning GPT Models](https://platform.openai.com/docs/guides/fine-tuning)- [Fine-Tuning GPT Models](https://platform.openai.com/docs/guides/fine-tuning)\n",
    "\n",
    "**Flowise***\n",
    "- [Flowise Website](https://flowiseai.com/)\n",
    "- [Flowise GitHub Repo](https://github.com/FlowiseAI/Flowise)- [Flowise GitHub Repo](https://github.com/FlowiseAI/Flowise)\n",
    "- [Flowise Documentation](https://docs.flowiseai.com/)cs.flowiseai.com/)\n",
    "- [Custom Tools in Flowise](https://docs.flowiseai.com/integrations/tools/custom-tool)- [Custom Tools in Flowise](https://docs.flowiseai.com/integrations/tools/custom-tool)\n",
    "\n",
    "**Google/DeepMind Gemini**\n",
    "- [Gemini Overview](https://deepmind.google/technologies/gemini/#build-with-gemini)mind.google/technologies/gemini/#build-with-gemini)\n",
    "- [Gemini 1 Report](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)- [Gemini 1 Report](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)\n",
    "- [Google AI](https://ai.google.dev/)\n",
    "- [Gemini App](https://gemini.google.com/app)- [Gemini App](https://gemini.google.com/app)\n",
    "- [Gemini API](https://blog.google/technology/ai/gemini-api-developers-cloud/)i-developers-cloud/)\n",
    "\n",
    "**Claude**\n",
    "- [Claude Overview](https://www.anthropic.com/index/claude-2-1)- [Claude Overview](https://www.anthropic.com/index/claude-2-1)\n",
    "- [Claude Pricing](https://www-files.anthropic.com/production/images/model_pricing_nov2023.pdf)om/production/images/model_pricing_nov2023.pdf)\n",
    "- [Anthropic Product Page](https://www.anthropic.com/product)- [Anthropic Product Page](https://www.anthropic.com/product)\n",
    "\n",
    "**Grok**\n",
    "- [Grok Overview](https://grok.x.ai/)\n",
    "- [Grok Website](https://x.ai/)- [Grok Website](https://x.ai/)\n",
    "\n",
    "**Hugging Face and HuggingChat**\n",
    "- [Hugging Face](https://huggingface.co/)\n",
    "- [HuggingChat](https://huggingface.co/chat/)- [HuggingChat](https://huggingface.co/chat/)\n",
    "\n",
    "**Mistral Mixture**\n",
    "- [Mistral Documentation](https://huggingface.co/docs/transformers/model_doc/mixtral)://huggingface.co/docs/transformers/model_doc/mixtral)\n",
    "- [Mistral Blog](https://huggingface.co/blog/mixtral)- [Mistral Blog](https://huggingface.co/blog/mixtral)\n",
    "- [Mixture of Experts (MoE)](https://huggingface.co/blog/moe)co/blog/moe)\n",
    "\n",
    "**Llama from Meta**\n",
    "- [Llama Overview](https://ai.meta.com/llama/)- [Llama Overview](https://ai.meta.com/llama/)\n",
    "\n",
    "**GitHub Repo for Orca**\n",
    "- [Orca GitHub Repo](https://github.com/scrippt-tech/orca)/orca)\n",
    "- [Open-Orca on Hugging Face](https://huggingface.co/Open-Orca)- [Open-Orca on Hugging Face](https://huggingface.co/Open-Orca)\n",
    "\n",
    "**POE**\n",
    "- [POE](https://poe.com/)\n",
    "\n",
    "**DALL-E from OpenAI**\n",
    "- [DALL-E Overview](https://openai.com/dall-e-3)- [DALL-E Overview](https://openai.com/dall-e-3)\n",
    "- [Labs for Editing Images](https://labs.openai.com/)ages](https://labs.openai.com/)\n",
    "- [DALL-E in Bing](https://www.bing.com/images/create)- [DALL-E in Bing](https://www.bing.com/images/create)\n",
    "\n",
    "**Adobe Firefly**\n",
    "- [Adobe Firefly](https://firefly.adobe.com/)\n",
    "\n",
    "**Texture Checker for Tiling**re Checker for Tiling**\n",
    "- [Texture Checker](https://www.pycheung.com/checker/)- [Texture Checker](https://www.pycheung.com/checker/)\n",
    "\n",
    "### **MidJourney**### **MidJourney**\n",
    "- [MidJourney Account](https://www.midjourney.com/account)ey Account](https://www.midjourney.com/account)\n",
    "- [MidJourney Explore](https://www.midjourney.com/explore)- [MidJourney Explore](https://www.midjourney.com/explore)\n",
    "\n",
    "### **Leonardo AI**### **Leonardo AI**\n",
    "- [Leonardo AI Login](https://leonardo.ai/)\n",
    "- [Getting Started with Leonardo AI](https://intercom.help/leonardo-ai/en/articles/8067649-getting-started-with-the-ai-image-generation-tool)- [Getting Started with Leonardo AI](https://intercom.help/leonardo-ai/en/articles/8067649-getting-started-with-the-ai-image-generation-tool)\n",
    "\n",
    "### **Stable Video Diffusion and Text-to-Video**### **Stable Video Diffusion and Text-to-Video**\n",
    "- [Stable Video Diffusion on Hugging Face](https://huggingface.co/spaces/multimodalart/stable-video-diffusion) Video Diffusion on Hugging Face](https://huggingface.co/spaces/multimodalart/stable-video-diffusion)\n",
    "- [RunwayML](https://runwayml.com/)- [RunwayML](https://runwayml.com/)\n",
    "\n",
    "### **Deforum Quick Guide**### **Deforum Quick Guide**\n",
    "- [Deforum Guide](https://stable-diffusion-art.com/deforum/)ide](https://stable-diffusion-art.com/deforum/)\n",
    "\n",
    "### **Colab Notebooks**\n",
    "- [Wav2Lip](https://colab.research.google.com/github/justinjohn0306/Wav2Lip/blob/master/Wav2Lip_simplified_v5.ipynb#scrollTo=vYxpPeie1CYL)- [Wav2Lip](https://colab.research.google.com/github/justinjohn0306/Wav2Lip/blob/master/Wav2Lip_simplified_v5.ipynb#scrollTo=vYxpPeie1CYL)\n",
    "- [Whisper Transcript](https://colab.research.google.com/drive/1bVx__zkunK--yQ1d_8DtcgKefLPG5cxV?usp=sharing#scrollTo=Zp7ix_bjsaJt)gle.com/drive/1bVx__zkunK--yQ1d_8DtcgKefLPG5cxV?usp=sharing#scrollTo=Zp7ix_bjsaJt)\n",
    "\n",
    "### **DreamBooth Colab Notebooks**ooks**\n",
    "- [DreamBooth on Hugging Face](https://colab.research.google.com/github/huggingface/autotrain-advanced/blob/main/colabs/AutoTrain_Dreambooth.ipynb#scrollTo=_LvIS7-7PcLT)- [DreamBooth on Hugging Face](https://colab.research.google.com/github/huggingface/autotrain-advanced/blob/main/colabs/AutoTrain_Dreambooth.ipynb#scrollTo=_LvIS7-7PcLT)\n",
    "\n",
    "### **ElevenLabs**### **ElevenLabs**\n",
    "- [ElevenLabs](https://elevenlabs.io/)\n",
    "\n",
    "### **AI Music**\n",
    "- [Suno AI](https://app.suno.ai/)- [Suno AI](https://app.suno.ai/)\n",
    "\n",
    "### **Selling on Platforms**### **Selling on Platforms**\n",
    "- [PromptBase](https://promptbase.com/)://promptbase.com/)\n",
    "- [Fiverr](https://www.fiverr.com/)- [Fiverr](https://www.fiverr.com/)\n",
    "- [Upwork](https://www.upwork.com/)ork.com/)\n",
    "\n",
    "### **Full-Time AI Jobs**\n",
    "- [Joblist AI](https://www.joblist.ai/)- [Joblist AI](https://www.joblist.ai/)\n",
    "- [Indeed](https://www.indeed.com/)\n",
    "\n",
    "### **Upscalers**\n",
    "- [Magnific AI](https://magnific.ai/)- [Magnific AI](https://magnific.ai/)\n",
    "- [Topaz Labs](https://www.topazlabs.com/topaz-photo-ai-denoise) Labs](https://www.topazlabs.com/topaz-photo-ai-denoise)\n",
    "\n",
    "### **Copyrights****\n",
    "- [OpenAI Copyrights](https://openai.com/blog/new-models-and-developer-products-announced-at-devday)- [OpenAI Copyrights](https://openai.com/blog/new-models-and-developer-products-announced-at-devday)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
